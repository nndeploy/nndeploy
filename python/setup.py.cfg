import sys
from setuptools import setup, find_packages
import os


try:
    from wheel.bdist_wheel import bdist_wheel as _bdist_wheel

    class bdist_wheel(_bdist_wheel):
        def finalize_options(self):
            _bdist_wheel.finalize_options(self)
            self.root_is_pure = False

except ImportError:
    bdist_wheel = None


if sys.version_info < (3, 0):
    sys.exit("Sorry, Python < 3.0 is not supported")


def parse_requirements(fname='requirements.txt', with_version=True):
    """
    Parse the package dependencies listed in a file but strips specific
    versioning information.

    Args:
        fname (str): path to the file
        with_version (bool, default=False): if True include version specs

    Returns:
        List[str]: list of requirements items

    CommandLine:
        python -c "import setup; print(setup.parse_requirements())"
    """
    import re
    import sys
    from os.path import exists
    require_fpath = fname

    def parse_line(line):
        """Parse information from a line in a requirements text file."""
        if line.startswith('-r '):
            # Allow specifying requirements in other files
            target = line.split(' ')[1]
            for info in parse_require_file(target):
                yield info
        else:
            info = {'line': line}
            if line.startswith('-e '):
                info['package'] = line.split('#egg=')[1]
            elif '@git+' in line:
                info['package'] = line
            else:
                # Remove versioning from the package
                pat = '(' + '|'.join(['>=', '==', '>']) + ')'
                parts = re.split(pat, line, maxsplit=1)
                parts = [p.strip() for p in parts]

                info['package'] = parts[0]
                if len(parts) > 1:
                    op, rest = parts[1:]
                    if ';' in rest:
                        # Handle platform specific dependencies
                        # http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies
                        version, platform_deps = map(str.strip,
                                                     rest.split(';'))
                        info['platform_deps'] = platform_deps
                    else:
                        version = rest  # NOQA
                    info['version'] = (op, version)
            yield info

    def parse_require_file(fpath):
        with open(fpath, 'r') as f:
            for line in f.readlines():
                line = line.strip()
                if line and not line.startswith('#'):
                    for info in parse_line(line):
                        yield info

    def gen_packages_items():
        if exists(require_fpath):
            for info in parse_require_file(require_fpath):
                parts = [info['package']]
                if with_version and 'version' in info:
                    parts.extend(info['version'])
                if not sys.version.startswith('3.4'):
                    # apparently package_deps are broken in 3.4
                    platform_deps = info.get('platform_deps')
                    if platform_deps is not None:
                        parts.append(';' + platform_deps)
                item = ''.join(parts)
                yield item

    packages = list(gen_packages_items())
    return packages


# 读取长描述
def read_long_description():
    """读取 README.md 文件作为长描述"""
    readme_path = "README.md"
    if os.path.exists(readme_path):
        try:
            with open(readme_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            print(f"警告：无法读取 {readme_path}: {e}")
    
    # 如果无法读取 README，使用默认描述
    return """
You can get everything in nndeploy github main page : [nndeploy](https://github.com/nndeploy/nndeploy)
"""


# def get_internal_so_path():
#     import importlib

#     suffixes = importlib.machinery.EXTENSION_SUFFIXES
#     loader = importlib.machinery.ExtensionFileLoader
#     lazy_loader = importlib.util.LazyLoader.factory(loader)
#     finder = importlib.machinery.FileFinder("nndeploy", (lazy_loader, suffixes))
#     spec = finder.find_spec("_nndeploy_internal")
#     pathname = spec.origin
#     assert os.path.isfile(pathname)
#     return os.path.basename(pathname)


# package_data = {"nndeploy": [get_internal_so_path()]}

def get_internal_so_path():
    import os
    import glob
    import platform
    import subprocess

    # 定义搜索路径
    search_path = "nndeploy"
    
    # 根据不同平台设置文件扩展名
    if platform.system() == "Windows":
        extensions = [".dll", ".pyd"]
    elif platform.system() == "Darwin":
        extensions = [".dylib", ".so"]
    else:  # Linux and others
        extensions = [".so"]  # 添加.so.*以匹配带版本号的动态库
        
    # 检查目录是否存在
    if not os.path.exists(search_path):
        raise FileNotFoundError(f"目录 {search_path} 不存在")
        
    # 查找所有动态库文件
    all_matches = []
    for ext in extensions:
        pattern = os.path.join(search_path, f"*{ext}*")  # 添加*以匹配带版本号的后缀
        matches = glob.glob(pattern)
        all_matches.extend(matches)
    
    if not all_matches:
        raise FileNotFoundError(f"在 {search_path} 目录下未找到动态库文件")
        
    # 打印找到的所有动态库文件
    print(f"在 {search_path} 目录下找到以下动态库文件:")
    for match in all_matches:
        print(f"  {os.path.basename(match)}")
        
    # 在Linux和macOS上建立动态库链接关系
    if platform.system() != "Windows":
        for lib_path in all_matches:
            try:
                # 使用ldd/otool查看依赖关系
                if platform.system() == "Darwin":
                    cmd = ["otool", "-L", lib_path]
                else:
                    cmd = ["ldd", lib_path]
                result = subprocess.run(cmd, capture_output=True, text=True)
                # print(f"\n{os.path.basename(lib_path)}的依赖关系:")
                # print(result.stdout)
                
                # 设置rpath
                if platform.system() == "Darwin":
                    subprocess.run(["install_name_tool", "-add_rpath", "@loader_path", lib_path])
                else:
                    subprocess.run(["patchelf", "--set-rpath", "$ORIGIN", lib_path])
            except Exception as e:
                print(f"警告: 处理{lib_path}时出错: {e}")
                
    # 返回所有动态库文件名列表
    return [os.path.basename(match) for match in all_matches]


def get_package_data():
    """获取需要打包的数据文件"""
    # 直接使用 get_internal_so_path() 返回的列表
    so_files = get_internal_so_path()
    
    # 确保返回一个字典，其值为一个简单的字符串列表
    package_data = {
        "nndeploy": so_files  # 这里 so_files 已经是一个字符串列表了
    }
    
    print(f"package_data: {package_data}")
    return package_data

# 检测CUDA是否可用以及版本
def get_cuda_version():
    try:
        import torch
        if torch.cuda.is_available():
            # 获取CUDA版本,例如 "11.8" 
            version = torch.version.cuda
            # 移除小数点,例如 "118"
            version_str = version.replace('.','')
            return version_str
    except:
        return None
    return None

cuda_version = get_cuda_version()

# 基础依赖包
install_requires = [
    'cython',  # Cython编译
    'packaging',  # 包管理
    'setuptools',  # 安装工具
    'gitpython>=3.1.30',  # Git操作
    'aiofiles>=24.1.0',  # 异步文件操作
    'PyYAML>=5.3.1',  # YAML解析
    'pytest',  # 测试框架
    'jsonschema',  # JSON Schema验证
    'multiprocess',  # 多进程支持
    'numpy',  # 数值计算
    'opencv-python>=4.8.0',  # 图像处理
]

# 根据CUDA版本添加对应的torch和onnxruntime
if cuda_version:
    install_requires.extend([
        f'torch>=2.0.0'  # PyTorch(GPU版本)
    ])
else:
    install_requires.extend([
        'torch>=2.0.0'  # PyTorch(CPU版本)
    ])

print(f"install_requires: {install_requires}")


setup(
    name="nndeploy",
    version="${PACKAGE_VERSION}",  # 修复版本号格式
    author="nndeploy team",
    author_email="595961667@qq.com",  # 添加邮箱
    description="Easy-to-use, high-performance, multi-platform AI inference deployment framework",  # 添加简短描述
    long_description=read_long_description(),  # 添加长描述
    long_description_content_type="text/markdown",  # 指定内容类型为 Markdown
    url="https://github.com/nndeploy/nndeploy",  # 添加项目URL
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: Apache Software License",
        "Operating System :: OS Independent",
        "Programming Language :: C++",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    license='Apache License 2.0',
    python_requires=">=3.8",
    packages=find_packages(),
    package_dir={"nndeploy": "nndeploy"},
    # package_data=package_data,
    package_data=get_package_data(),
    install_requires=install_requires,
    # extras_require={
    #     "all": parse_requirements('../requirements.txt')
    # },
    cmdclass={"bdist_wheel": bdist_wheel},
    keywords="deep-learning, neural-network, model-deployment, inference, ai",
    project_urls={
        "Bug Reports": "https://github.com/nndeploy/nndeploy/issues",
        "Source": "https://github.com/nndeploy/nndeploy",
    },
)